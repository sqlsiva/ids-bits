{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bda93ba",
   "metadata": {
    "id": "9bda93ba"
   },
   "source": [
    "# <center>        **Introduction to Data Science (S2-22_DSECLZG532)-ASSIGNMENT**</center>\n",
    "\n",
    "## Group No 170\n",
    "\n",
    "## Group Member Names:\n",
    "\n",
    "1. R. SIVASHANKAR     (BITS ID\t: 2022dc04277)\n",
    "2. NIKHIL SOBTI\t      (BITS ID\t: 2022dc04432)\n",
    "3. MANISH KUMAR SONAR (BITS ID\t: 2022dc04450)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d80c60",
   "metadata": {
    "id": "f5d80c60"
   },
   "source": [
    "# 1. Business Understanding\n",
    "\n",
    "Students are expected to identify an analytical problem of your choice. You have to detail the Business Understanding part of your problem under this heading which basically addresses the following questions.\n",
    "\n",
    "   1. What is the business problem that you are trying to solve?\n",
    "   2. What data do you need to answer the above problem?\n",
    "   3. What are the different sources of data?\n",
    "   4. What kind of analytics task are you performing?\n",
    "\n",
    "Score: 1 Mark in total (0.25 mark each)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3298e121",
   "metadata": {
    "id": "3298e121"
   },
   "source": [
    "--------------Type the answers below this line--------------\n",
    "1. What is the business problem that you are trying to solve?\n",
    "Answer :- To create a new winning team for next IPL tournament.\n",
    "\n",
    "2. What data do you need to answer the above problem?\n",
    "Answer :- Last 12 years of IPL tournaments data to analyse bowl by bowl action and to evaluate individual performance and key skills of players who can form a winning team for next IPL tournament.\n",
    "\n",
    "3. What are the different sources of data?\n",
    "Answer :- Two open data sources as mentioned below:\n",
    "            a) IPL Matches dataset for period 2008-2020\n",
    "            b) IPL Ball-by-Ball dataset for period 2008-2020\n",
    "            \n",
    "4. What kind of analytics task are you performing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8e0cb",
   "metadata": {
    "id": "3cc8e0cb"
   },
   "source": [
    "# 2. Data Acquisition\n",
    "\n",
    "For the problem identified , find an appropriate data set (Your data set must\n",
    "be unique with minimum **20 features and 10k rows**) from any public data source.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## 2.1 Download the data directly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b51d895",
   "metadata": {
    "id": "4b51d895"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "import urllib.request\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.kaggle.com/datasets/patrickb1912/ipl-complete-dataset-20082020?select=IPL+Ball-by-Ball+2008-2020.csv'\n",
    "response = urllib.request.urlopen(url)\n",
    "data_lines = response.read().decode().splitlines()\n",
    "\n",
    "url = 'https://www.kaggle.com/datasets/patrickb1912/ipl-complete-dataset-20082020?select=IPL+Matches+2008-2020.csv'\n",
    "response = urllib.request.urlopen(url)\n",
    "data_lines = response.read().decode().splitlines()\n",
    "\n",
    "# need code to merge both of above csv to form  one data frame for next actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f49f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Test-Wroking-Python-Kernal\n"
     ]
    }
   ],
   "source": [
    "print('--Test-Wroking-Python-Kernal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49530d0c",
   "metadata": {
    "id": "49530d0c"
   },
   "source": [
    "## 2.2 Code for converting the above downloaded data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f4c171",
   "metadata": {
    "id": "c1f4c171"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0 columns passed, passed data had 90 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 0 columns passed, passed data had 90 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19184\\318388025.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Assuming the first row contains column headings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# Removing the first row (column headings)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[1;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[0;32m    722\u001b[0m                         \u001b[1;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                         \u001b[1;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m     \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 0 columns passed, passed data had 90 columns"
     ]
    }
   ],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "data = []\n",
    "csv_reader = csv.reader(data_lines)\n",
    "for row in csv_reader:\n",
    "    data.append(row)\n",
    "columns = data[0]  # Assuming the first row contains column headings\n",
    "data = data[1:]    # Removing the first row (column headings)\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fea4d",
   "metadata": {
    "id": "7b1fea4d"
   },
   "source": [
    "## 2.3 Confirm the data has been correctly by displaying the first 5 and last 5 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e6c58",
   "metadata": {
    "id": "624e6c58"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "print(\"First 5 records:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nLast 5 records:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb84fc56",
   "metadata": {
    "id": "bb84fc56"
   },
   "source": [
    "## 2.4 Display the column headings, statistical information, description and statistical summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ad28e",
   "metadata": {
    "id": "086ad28e"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "print(\"\\nColumn Headings:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nStatistical Information:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nDescription:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812edb18",
   "metadata": {
    "id": "812edb18"
   },
   "source": [
    "## 2.5 Write your observations from the above.\n",
    "1. Size of the dataset\n",
    "2. What type of data attributes are there?\n",
    "3. Is there any null data that has to be cleaned?\n",
    "\n",
    "Score: 2 Marks in total (0.25 marks for 2.1, 0.25 marks for 2.2, 0.5 marks for 2.3, 0.25 marks for 2.4, 0.75 marks for 2.5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60d80d2f",
   "metadata": {
    "id": "60d80d2f"
   },
   "source": [
    "--------------Type the answers below this line--------------\n",
    "1. Size of the dataset\n",
    "Answer :- 193469 rows and 34 columns/features\n",
    "\n",
    "2. What type of data attributes are there?\n",
    "Answer :- Match outcomes, Player achievements, venue details and ????????\n",
    "\n",
    "\n",
    "3. Is there any null data that has to be cleaned?\n",
    "Answer :- Yes ??????????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e0e36",
   "metadata": {
    "id": "102e0e36"
   },
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "637cb469",
   "metadata": {
    "id": "637cb469"
   },
   "source": [
    "If input data is numerical or categorical, do 3.1, 3.2 and 3.4\n",
    "If input data is text, do 3.3 and 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb953b",
   "metadata": {
    "id": "2bcb953b"
   },
   "source": [
    "## 3.1 Check for\n",
    "\n",
    "* duplicate data\n",
    "* missing data\n",
    "* data inconsistencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b960e",
   "metadata": {
    "id": "5a5b960e"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "\n",
    "print(\"\\nMissing Data:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDuplicate Data:\")\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdebf8",
   "metadata": {
    "id": "06fdebf8"
   },
   "source": [
    "## 3.2 Apply techiniques\n",
    "* to remove duplicate data\n",
    "* to impute or remove missing data\n",
    "* to remove data inconsistencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3118eb",
   "metadata": {
    "id": "dd3118eb"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139fedf",
   "metadata": {
    "id": "2139fedf"
   },
   "source": [
    "## 3.3 Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6886fc",
   "metadata": {
    "id": "da6886fc"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "df['category'] = pd.factorize(df['category'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a2917",
   "metadata": {
    "id": "ae5a2917"
   },
   "source": [
    "## 3.4 Text data\n",
    "\n",
    "1. Remove special characters\n",
    "2. Change the case (up-casing and down-casing).\n",
    "3. Tokenization — process of discretizing words within a document.\n",
    "4. Filter Stop Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d5b0b",
   "metadata": {
    "id": "c86d5b0b"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "df = df.applymap(lambda x: x.replace('$', '').replace('%', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2cdee",
   "metadata": {
    "id": "a3b2cdee"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "# Assuming you have a text column 'text_data'\n",
    "# Checking for duplicate data, missing data, and removing special characters\n",
    "df['text_data'] = df['text_data'].apply(lambda x: x.replace('$', '').replace('%', '') if isinstance(x, str) else x)\n",
    "df.drop_duplicates(subset=['text_data'], inplace=True)\n",
    "df.dropna(subset=['text_data'], inplace=True)\n",
    "\n",
    "# Changing case and tokenization\n",
    "df['text_data'] = df['text_data'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df['text_data_tokens'] = df['text_data'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "# Filtering stop words (assuming a list of stop words)\n",
    "stop_words = ['and', 'the', 'is', 'in', 'it', 'of', 'to']\n",
    "df['text_data_tokens'] = df['text_data_tokens'].apply(lambda tokens: [token for token in tokens if token not in stop_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cec4fc",
   "metadata": {
    "id": "e3cec4fc"
   },
   "source": [
    "## 3.4 Report\n",
    "\n",
    "Mention and justify the method adopted\n",
    "* to remove duplicate data, if present\n",
    "* to impute or remove missing data, if present\n",
    "* to remove data inconsistencies, if present\n",
    "\n",
    "OR for textdata\n",
    "* How many tokens after step 3?\n",
    "* how may tokens after stop words filtering?\n",
    "\n",
    "If the any of the above are not present, then also add in the report below.\n",
    "\n",
    "Score: 2 Marks (based on the dataset you have, the data prepreation you had to do and report typed, marks will be distributed between 3.1, 3.2, 3.3 and 3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab84ce6",
   "metadata": {
    "id": "3ab84ce6"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "\n",
    "# Step 7: Identifying and preprocessing target variable\n",
    "# Assuming the target column is 'target'\n",
    "target_column = 'target'\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Assuming you want to encode the target variable\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Report observations\n",
    "print(\"\\nObservations:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Print the preprocessed DataFrame\n",
    "print(\"\\nPreprocessed DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fea7e8",
   "metadata": {
    "id": "f0fea7e8"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cd04b",
   "metadata": {
    "id": "793cd04b"
   },
   "source": [
    "## 3.5 Identify the target variables.\n",
    "\n",
    "* Separate the data from the target such that the dataset is in the form of (X,y) or (Features, Label)\n",
    "\n",
    "* Discretize / Encode the target variable or perform one-hot encoding on the target or any other as and if required.\n",
    "\n",
    "* Report the observations\n",
    "\n",
    "Score: 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9089b57",
   "metadata": {
    "id": "c9089b57"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0b5d2",
   "metadata": {
    "id": "3ae0b5d2"
   },
   "source": [
    "# 4. Data Exploration using various plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bf4d7",
   "metadata": {
    "id": "186bf4d7"
   },
   "source": [
    "## 4.1 Scatter plot of each quantitative attribute with the target.\n",
    "\n",
    "Score: 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d7b27",
   "metadata": {
    "id": "868d7b27"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f9e37",
   "metadata": {
    "id": "575f9e37"
   },
   "source": [
    "## 4.2 EDA using visuals\n",
    "* Use (minimum) 2 plots (pair plot, heat map, correlation plot, regression plot...) to identify the optimal set of attributes that can be used for classification.\n",
    "* Name them, explain why you think they can be helpful in the task and perform the plot as well. Unless proper justification for the choice of plots given, no credit will be awarded.\n",
    "\n",
    "Score: 2 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d614311",
   "metadata": {
    "id": "4d614311"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc82a1",
   "metadata": {
    "id": "bdbc82a1"
   },
   "source": [
    "# 5. Data Wrangling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca214eb3",
   "metadata": {
    "id": "ca214eb3"
   },
   "source": [
    "## 5.1 Univariate Filters\n",
    "\n",
    "#### Numerical and Categorical Data\n",
    "* Identify top 5 significant features by evaluating each feature independently with respect to the target variable by exploring\n",
    "1. Mutual Information (Information Gain)\n",
    "2. Gini index\n",
    "3. Gain Ratio\n",
    "4. Chi-Squared test\n",
    "5. Fisher Score\n",
    "(From the above 5 you are required to use only any <b>two</b>)\n",
    "\n",
    "#### For Text data\n",
    "\n",
    "1. Stemming / Lemmatization.\n",
    "2. Forming n-grams and storing them in the document vector.\n",
    "3. TF-IDF\n",
    "(From the above 2 you are required to use only any <b>two</b>)\n",
    "\n",
    "\n",
    "Score: 3 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e9754",
   "metadata": {
    "id": "a85e9754"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38031f24",
   "metadata": {
    "id": "38031f24"
   },
   "source": [
    "## 5.2 Report observations\n",
    "\n",
    "Write your observations from the results of each method. Clearly justify your choice of the method.\n",
    "\n",
    "Score 1 mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7a3a8",
   "metadata": {
    "id": "85c7a3a8"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1173c",
   "metadata": {
    "id": "06f1173c"
   },
   "source": [
    "# 6. Implement Machine Learning Techniques\n",
    "\n",
    "Use any 2 ML algorithms\n",
    "1. Classification -- Decision Tree classifier\n",
    "\n",
    "2. Clustering -- kmeans\n",
    "\n",
    "3. Association Analysis\n",
    "\n",
    "4. Anomaly detection\n",
    "\n",
    "5. Textual data -- Naive Bayes classifier (not taught in this course)\n",
    "\n",
    "A clear justification have to be given for why a certain algorithm was chosen to address your problem.\n",
    "\n",
    "Score: 4 Marks (2 marks each for each algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040afed8",
   "metadata": {
    "id": "040afed8"
   },
   "source": [
    "## 6.1 ML technique 1 + Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042235d",
   "metadata": {
    "id": "7042235d"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610ca8c",
   "metadata": {
    "id": "f610ca8c"
   },
   "source": [
    "## 6.2 ML technique 2 + Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75e079",
   "metadata": {
    "id": "9b75e079"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57940c",
   "metadata": {
    "id": "eb57940c"
   },
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Compare the performance of the ML techniques used.\n",
    "\n",
    "Derive values for preformance study metrics like accuracy, precision, recall, F1 Score, AUC-ROC etc to compare the ML algos and plot them. A proper comparision based on different metrics should be done and not just accuracy alone, only then the comparision becomes authentic. You may use Confusion matrix, classification report, Word cloud etc as per the requirement of your application/problem.\n",
    "\n",
    "Score 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf06eb1",
   "metadata": {
    "id": "9bf06eb1"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed0137",
   "metadata": {
    "id": "79ed0137"
   },
   "source": [
    "## 8. Solution\n",
    "\n",
    "What is the solution that is proposed to solve the business problem discussed in Section 1. Also share your learnings while working through solving the problem in terms of challenges, observations, decisions made etc.\n",
    "\n",
    "Score 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324448eb",
   "metadata": {
    "id": "324448eb"
   },
   "source": [
    "--------------Type the answers below this line--------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68ab61d5",
   "metadata": {
    "id": "68ab61d5"
   },
   "source": [
    "##---------Type the answer below this line------------------##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RcDDQlfbZQ7E",
   "metadata": {
    "id": "RcDDQlfbZQ7E"
   },
   "source": [
    "##NOTE\n",
    "All Late Submissions will incur a penalty of -2 marks. Do ensure on time submission to avoid penalty.\n",
    "\n",
    "Good Luck!!!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
